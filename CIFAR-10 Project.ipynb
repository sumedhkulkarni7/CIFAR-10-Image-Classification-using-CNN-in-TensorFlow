{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10 Project\n",
    "\n",
    "### CNN with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put file path as a string here\n",
    "CIFAR_DIR = 'D:/Self.Study/Udemy - Complete guide to Tensorflow - Jose Portilla/FULL-TENSORFLOW-NOTES-AND-DATA/Tensorflow-Bootcamp-master/03-Convolutional-Neural-Networks/cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        cifar_dict = pickle.load(fo, encoding='bytes')\n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, direc in zip(all_data, dirs):\n",
    "    all_data[i] = unpickle(CIFAR_DIR + direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_meta = all_data[0]\n",
    "data_batch1 = all_data[1]\n",
    "data_batch2 = all_data[2]\n",
    "data_batch3 = all_data[3]\n",
    "data_batch4 = all_data[4]\n",
    "data_batch5 = all_data[5]\n",
    "test_batch = all_data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch1.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a single image using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_batch1[b\"data\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[0]/255).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dad7002b0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Dealing With Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=10):\n",
    "    '''\n",
    "    For use to one-hot encode the 10- possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarHelper():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
    "        self.test_batch = [test_batch]\n",
    "        \n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        \n",
    "        self.training_images = np.vstack([d[b\"data\"] for d in self.all_train_batches])\n",
    "        train_len = len(self.training_images)\n",
    "        \n",
    "        self.training_images = self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        self.training_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        \n",
    "        self.test_images = np.vstack([d[b\"data\"] for d in self.test_batch])\n",
    "        test_len = len(self.test_images)\n",
    "        \n",
    "        self.test_images = self.test_images.reshape(test_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        self.test_labels = one_hot_encode(np.hstack([d[b\"labels\"] for d in self.test_batch]), 10)\n",
    "\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(100,32,32,3)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Up Training Images and Labels\n",
      "Setting Up Test Images and Labels\n"
     ]
    }
   ],
   "source": [
    "# Before Your tf.Session run these two lines\n",
    "ch = CifarHelper()\n",
    "ch.set_up_images()\n",
    "\n",
    "# During your session to grab the next batch use this line\n",
    "# (Just like we did for mnist.train.next_batch)\n",
    "# batch = ch.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "#### Import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingsumedh\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create 2 placeholders, x and y_true. Their shapes should be: **\n",
    "\n",
    "* x shape = [None,32,32,3]\n",
    "* y_true shape = [None,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,32,32,3])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create one more placeholder called hold_prob. No need for shape here. This placeholder will just hold a single probability for the dropout. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "** Grab the helper functions from MNIST with CNN (or recreate them here yourself for a hard challenge!). You'll need: **\n",
    "\n",
    "* init_weights\n",
    "* init_bias\n",
    "* conv2d\n",
    "* max_pool_2by2\n",
    "* convolutional_layer\n",
    "* normal_full_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Layers\n",
    "\n",
    "** Create a convolutional layer and a pooling layer as we did for MNIST. **\n",
    "** Its up to you what the 2d size of the convolution should be, but the last two digits need to be 3 and 32 because of the 3 color channels and 32 pixels. So for example you could use:**\n",
    "\n",
    "        convo_1 = convolutional_layer(x,shape=[4,4,3,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,3,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the next convolutional and pooling layers.  The last two dimensions of the convo_2 layer should be 32,64 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a flattened layer by reshaping the pooling layer into [-1,8 * 8 * 64] or [-1,4096] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*8*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,8*8*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a new full layer using the normal_full_layer function and passing in your flattend convolutional 2 layer with size=1024. (You could also choose to reduce this to something like 512)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create the dropout layer with tf.nn.dropout, remember to pass in your hold_prob placeholder. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Finally set the output to y_pred by passing in the dropout layer into the normal_full_layer function. The size should be 10 because of the 10 possible labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "** Create a cross_entropy loss function **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "** Create the optimizer using an Adam Optimizer. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a variable to intialize all the global tf variables. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Session\n",
    "\n",
    "** Perform the training and test print outs in a Tf session and run your model! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.1167\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.315\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.3811\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.4038\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.4273\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.4405\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.4601\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.4768\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.4817\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.4898\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.4992\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.5012\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.5076\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.5165\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.5169\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.5267\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.5298\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.5395\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.5441\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.5426\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.5559\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.5568\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.555\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.5641\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.5672\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.5693\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.5707\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.5763\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.578\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.585\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.5841\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "0.5855\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.5901\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.5974\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.5929\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "0.5954\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.6028\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "0.6017\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "0.6087\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.6111\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is:\n",
      "0.6157\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is:\n",
      "0.6125\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is:\n",
      "0.6119\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is:\n",
      "0.6169\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is:\n",
      "0.6218\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is:\n",
      "0.6234\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is:\n",
      "0.6199\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is:\n",
      "0.6218\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is:\n",
      "0.6254\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is:\n",
      "0.6277\n",
      "\n",
      "\n",
      "Currently on step 5000\n",
      "Accuracy is:\n",
      "0.6277\n",
      "\n",
      "\n",
      "Currently on step 5100\n",
      "Accuracy is:\n",
      "0.6327\n",
      "\n",
      "\n",
      "Currently on step 5200\n",
      "Accuracy is:\n",
      "0.6299\n",
      "\n",
      "\n",
      "Currently on step 5300\n",
      "Accuracy is:\n",
      "0.6349\n",
      "\n",
      "\n",
      "Currently on step 5400\n",
      "Accuracy is:\n",
      "0.6354\n",
      "\n",
      "\n",
      "Currently on step 5500\n",
      "Accuracy is:\n",
      "0.6388\n",
      "\n",
      "\n",
      "Currently on step 5600\n",
      "Accuracy is:\n",
      "0.6403\n",
      "\n",
      "\n",
      "Currently on step 5700\n",
      "Accuracy is:\n",
      "0.6382\n",
      "\n",
      "\n",
      "Currently on step 5800\n",
      "Accuracy is:\n",
      "0.642\n",
      "\n",
      "\n",
      "Currently on step 5900\n",
      "Accuracy is:\n",
      "0.6434\n",
      "\n",
      "\n",
      "Currently on step 6000\n",
      "Accuracy is:\n",
      "0.6456\n",
      "\n",
      "\n",
      "Currently on step 6100\n",
      "Accuracy is:\n",
      "0.6449\n",
      "\n",
      "\n",
      "Currently on step 6200\n",
      "Accuracy is:\n",
      "0.6421\n",
      "\n",
      "\n",
      "Currently on step 6300\n",
      "Accuracy is:\n",
      "0.6539\n",
      "\n",
      "\n",
      "Currently on step 6400\n",
      "Accuracy is:\n",
      "0.649\n",
      "\n",
      "\n",
      "Currently on step 6500\n",
      "Accuracy is:\n",
      "0.656\n",
      "\n",
      "\n",
      "Currently on step 6600\n",
      "Accuracy is:\n",
      "0.6529\n",
      "\n",
      "\n",
      "Currently on step 6700\n",
      "Accuracy is:\n",
      "0.6487\n",
      "\n",
      "\n",
      "Currently on step 6800\n",
      "Accuracy is:\n",
      "0.6535\n",
      "\n",
      "\n",
      "Currently on step 6900\n",
      "Accuracy is:\n",
      "0.6571\n",
      "\n",
      "\n",
      "Currently on step 7000\n",
      "Accuracy is:\n",
      "0.6589\n",
      "\n",
      "\n",
      "Currently on step 7100\n",
      "Accuracy is:\n",
      "0.659\n",
      "\n",
      "\n",
      "Currently on step 7200\n",
      "Accuracy is:\n",
      "0.655\n",
      "\n",
      "\n",
      "Currently on step 7300\n",
      "Accuracy is:\n",
      "0.6585\n",
      "\n",
      "\n",
      "Currently on step 7400\n",
      "Accuracy is:\n",
      "0.6575\n",
      "\n",
      "\n",
      "Currently on step 7500\n",
      "Accuracy is:\n",
      "0.662\n",
      "\n",
      "\n",
      "Currently on step 7600\n",
      "Accuracy is:\n",
      "0.6682\n",
      "\n",
      "\n",
      "Currently on step 7700\n",
      "Accuracy is:\n",
      "0.6558\n",
      "\n",
      "\n",
      "Currently on step 7800\n",
      "Accuracy is:\n",
      "0.6653\n",
      "\n",
      "\n",
      "Currently on step 7900\n",
      "Accuracy is:\n",
      "0.665\n",
      "\n",
      "\n",
      "Currently on step 8000\n",
      "Accuracy is:\n",
      "0.6698\n",
      "\n",
      "\n",
      "Currently on step 8100\n",
      "Accuracy is:\n",
      "0.6688\n",
      "\n",
      "\n",
      "Currently on step 8200\n",
      "Accuracy is:\n",
      "0.666\n",
      "\n",
      "\n",
      "Currently on step 8300\n",
      "Accuracy is:\n",
      "0.6741\n",
      "\n",
      "\n",
      "Currently on step 8400\n",
      "Accuracy is:\n",
      "0.6676\n",
      "\n",
      "\n",
      "Currently on step 8500\n",
      "Accuracy is:\n",
      "0.6736\n",
      "\n",
      "\n",
      "Currently on step 8600\n",
      "Accuracy is:\n",
      "0.6764\n",
      "\n",
      "\n",
      "Currently on step 8700\n",
      "Accuracy is:\n",
      "0.6651\n",
      "\n",
      "\n",
      "Currently on step 8800\n",
      "Accuracy is:\n",
      "0.6688\n",
      "\n",
      "\n",
      "Currently on step 8900\n",
      "Accuracy is:\n",
      "0.6759\n",
      "\n",
      "\n",
      "Currently on step 9000\n",
      "Accuracy is:\n",
      "0.674\n",
      "\n",
      "\n",
      "Currently on step 9100\n",
      "Accuracy is:\n",
      "0.6778\n",
      "\n",
      "\n",
      "Currently on step 9200\n",
      "Accuracy is:\n",
      "0.6673\n",
      "\n",
      "\n",
      "Currently on step 9300\n",
      "Accuracy is:\n",
      "0.6786\n",
      "\n",
      "\n",
      "Currently on step 9400\n",
      "Accuracy is:\n",
      "0.6756\n",
      "\n",
      "\n",
      "Currently on step 9500\n",
      "Accuracy is:\n",
      "0.6812\n",
      "\n",
      "\n",
      "Currently on step 9600\n",
      "Accuracy is:\n",
      "0.6848\n",
      "\n",
      "\n",
      "Currently on step 9700\n",
      "Accuracy is:\n",
      "0.6689\n",
      "\n",
      "\n",
      "Currently on step 9800\n",
      "Accuracy is:\n",
      "0.6802\n",
      "\n",
      "\n",
      "Currently on step 9900\n",
      "Accuracy is:\n",
      "0.6785\n",
      "\n",
      "\n",
      "Currently on step 10000\n",
      "Accuracy is:\n",
      "0.6844\n",
      "\n",
      "\n",
      "Currently on step 10100\n",
      "Accuracy is:\n",
      "0.6864\n",
      "\n",
      "\n",
      "Currently on step 10200\n",
      "Accuracy is:\n",
      "0.678\n",
      "\n",
      "\n",
      "Currently on step 10300\n",
      "Accuracy is:\n",
      "0.6833\n",
      "\n",
      "\n",
      "Currently on step 10400\n",
      "Accuracy is:\n",
      "0.6829\n",
      "\n",
      "\n",
      "Currently on step 10500\n",
      "Accuracy is:\n",
      "0.6888\n",
      "\n",
      "\n",
      "Currently on step 10600\n",
      "Accuracy is:\n",
      "0.6913\n",
      "\n",
      "\n",
      "Currently on step 10700\n",
      "Accuracy is:\n",
      "0.6834\n",
      "\n",
      "\n",
      "Currently on step 10800\n",
      "Accuracy is:\n",
      "0.6881\n",
      "\n",
      "\n",
      "Currently on step 10900\n",
      "Accuracy is:\n",
      "0.6856\n",
      "\n",
      "\n",
      "Currently on step 11000\n",
      "Accuracy is:\n",
      "0.6895\n",
      "\n",
      "\n",
      "Currently on step 11100\n",
      "Accuracy is:\n",
      "0.6909\n",
      "\n",
      "\n",
      "Currently on step 11200\n",
      "Accuracy is:\n",
      "0.6872\n",
      "\n",
      "\n",
      "Currently on step 11300\n",
      "Accuracy is:\n",
      "0.6918\n",
      "\n",
      "\n",
      "Currently on step 11400\n",
      "Accuracy is:\n",
      "0.6843\n",
      "\n",
      "\n",
      "Currently on step 11500\n",
      "Accuracy is:\n",
      "0.6902\n",
      "\n",
      "\n",
      "Currently on step 11600\n",
      "Accuracy is:\n",
      "0.6941\n",
      "\n",
      "\n",
      "Currently on step 11700\n",
      "Accuracy is:\n",
      "0.6914\n",
      "\n",
      "\n",
      "Currently on step 11800\n",
      "Accuracy is:\n",
      "0.6844\n",
      "\n",
      "\n",
      "Currently on step 11900\n",
      "Accuracy is:\n",
      "0.6915\n",
      "\n",
      "\n",
      "Currently on step 12000\n",
      "Accuracy is:\n",
      "0.6945\n",
      "\n",
      "\n",
      "Currently on step 12100\n",
      "Accuracy is:\n",
      "0.6927\n",
      "\n",
      "\n",
      "Currently on step 12200\n",
      "Accuracy is:\n",
      "0.6913\n",
      "\n",
      "\n",
      "Currently on step 12300\n",
      "Accuracy is:\n",
      "0.6941\n",
      "\n",
      "\n",
      "Currently on step 12400\n",
      "Accuracy is:\n",
      "0.6909\n",
      "\n",
      "\n",
      "Currently on step 12500\n",
      "Accuracy is:\n",
      "0.6971\n",
      "\n",
      "\n",
      "Currently on step 12600\n",
      "Accuracy is:\n",
      "0.6979\n",
      "\n",
      "\n",
      "Currently on step 12700\n",
      "Accuracy is:\n",
      "0.6922\n",
      "\n",
      "\n",
      "Currently on step 12800\n",
      "Accuracy is:\n",
      "0.6925\n",
      "\n",
      "\n",
      "Currently on step 12900\n",
      "Accuracy is:\n",
      "0.6955\n",
      "\n",
      "\n",
      "Currently on step 13000\n",
      "Accuracy is:\n",
      "0.6983\n",
      "\n",
      "\n",
      "Currently on step 13100\n",
      "Accuracy is:\n",
      "0.7007\n",
      "\n",
      "\n",
      "Currently on step 13200\n",
      "Accuracy is:\n",
      "0.6968\n",
      "\n",
      "\n",
      "Currently on step 13300\n",
      "Accuracy is:\n",
      "0.6904\n",
      "\n",
      "\n",
      "Currently on step 13400\n",
      "Accuracy is:\n",
      "0.6947\n",
      "\n",
      "\n",
      "Currently on step 13500\n",
      "Accuracy is:\n",
      "0.6938\n",
      "\n",
      "\n",
      "Currently on step 13600\n",
      "Accuracy is:\n",
      "0.7044\n",
      "\n",
      "\n",
      "Currently on step 13700\n",
      "Accuracy is:\n",
      "0.6951\n",
      "\n",
      "\n",
      "Currently on step 13800\n",
      "Accuracy is:\n",
      "0.6997\n",
      "\n",
      "\n",
      "Currently on step 13900\n",
      "Accuracy is:\n",
      "0.6878\n",
      "\n",
      "\n",
      "Currently on step 14000\n",
      "Accuracy is:\n",
      "0.7021\n",
      "\n",
      "\n",
      "Currently on step 14100\n",
      "Accuracy is:\n",
      "0.7045\n",
      "\n",
      "\n",
      "Currently on step 14200\n",
      "Accuracy is:\n",
      "0.7032\n",
      "\n",
      "\n",
      "Currently on step 14300\n",
      "Accuracy is:\n",
      "0.6958\n",
      "\n",
      "\n",
      "Currently on step 14400\n",
      "Accuracy is:\n",
      "0.6999\n",
      "\n",
      "\n",
      "Currently on step 14500\n",
      "Accuracy is:\n",
      "0.7037\n",
      "\n",
      "\n",
      "Currently on step 14600\n",
      "Accuracy is:\n",
      "0.706\n",
      "\n",
      "\n",
      "Currently on step 14700\n",
      "Accuracy is:\n",
      "0.702\n",
      "\n",
      "\n",
      "Currently on step 14800\n",
      "Accuracy is:\n",
      "0.7019\n",
      "\n",
      "\n",
      "Currently on step 14900\n",
      "Accuracy is:\n",
      "0.6979\n",
      "\n",
      "\n",
      "Currently on step 15000\n",
      "Accuracy is:\n",
      "0.7026\n",
      "\n",
      "\n",
      "Currently on step 15100\n",
      "Accuracy is:\n",
      "0.7062\n",
      "\n",
      "\n",
      "Currently on step 15200\n",
      "Accuracy is:\n",
      "0.7034\n",
      "\n",
      "\n",
      "Currently on step 15300\n",
      "Accuracy is:\n",
      "0.7011\n",
      "\n",
      "\n",
      "Currently on step 15400\n",
      "Accuracy is:\n",
      "0.696\n",
      "\n",
      "\n",
      "Currently on step 15500\n",
      "Accuracy is:\n",
      "0.707\n",
      "\n",
      "\n",
      "Currently on step 15600\n",
      "Accuracy is:\n",
      "0.7071\n",
      "\n",
      "\n",
      "Currently on step 15700\n",
      "Accuracy is:\n",
      "0.705\n",
      "\n",
      "\n",
      "Currently on step 15800\n",
      "Accuracy is:\n",
      "0.7009\n",
      "\n",
      "\n",
      "Currently on step 15900\n",
      "Accuracy is:\n",
      "0.702\n",
      "\n",
      "\n",
      "Currently on step 16000\n",
      "Accuracy is:\n",
      "0.7069\n",
      "\n",
      "\n",
      "Currently on step 16100\n",
      "Accuracy is:\n",
      "0.7067\n",
      "\n",
      "\n",
      "Currently on step 16200\n",
      "Accuracy is:\n",
      "0.7073\n",
      "\n",
      "\n",
      "Currently on step 16300\n",
      "Accuracy is:\n",
      "0.7034\n",
      "\n",
      "\n",
      "Currently on step 16400\n",
      "Accuracy is:\n",
      "0.7013\n",
      "\n",
      "\n",
      "Currently on step 16500\n",
      "Accuracy is:\n",
      "0.7076\n",
      "\n",
      "\n",
      "Currently on step 16600\n",
      "Accuracy is:\n",
      "0.7082\n",
      "\n",
      "\n",
      "Currently on step 16700\n",
      "Accuracy is:\n",
      "0.705\n",
      "\n",
      "\n",
      "Currently on step 16800\n",
      "Accuracy is:\n",
      "0.7048\n",
      "\n",
      "\n",
      "Currently on step 16900\n",
      "Accuracy is:\n",
      "0.7013\n",
      "\n",
      "\n",
      "Currently on step 17000\n",
      "Accuracy is:\n",
      "0.7077\n",
      "\n",
      "\n",
      "Currently on step 17100\n",
      "Accuracy is:\n",
      "0.7124\n",
      "\n",
      "\n",
      "Currently on step 17200\n",
      "Accuracy is:\n",
      "0.7117\n",
      "\n",
      "\n",
      "Currently on step 17300\n",
      "Accuracy is:\n",
      "0.7035\n",
      "\n",
      "\n",
      "Currently on step 17400\n",
      "Accuracy is:\n",
      "0.6953\n",
      "\n",
      "\n",
      "Currently on step 17500\n",
      "Accuracy is:\n",
      "0.7115\n",
      "\n",
      "\n",
      "Currently on step 17600\n",
      "Accuracy is:\n",
      "0.7089\n",
      "\n",
      "\n",
      "Currently on step 17700\n",
      "Accuracy is:\n",
      "0.7119\n",
      "\n",
      "\n",
      "Currently on step 17800\n",
      "Accuracy is:\n",
      "0.7098\n",
      "\n",
      "\n",
      "Currently on step 17900\n",
      "Accuracy is:\n",
      "0.6998\n",
      "\n",
      "\n",
      "Currently on step 18000\n",
      "Accuracy is:\n",
      "0.7103\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 18100\n",
      "Accuracy is:\n",
      "0.7075\n",
      "\n",
      "\n",
      "Currently on step 18200\n",
      "Accuracy is:\n",
      "0.7115\n",
      "\n",
      "\n",
      "Currently on step 18300\n",
      "Accuracy is:\n",
      "0.7047\n",
      "\n",
      "\n",
      "Currently on step 18400\n",
      "Accuracy is:\n",
      "0.7024\n",
      "\n",
      "\n",
      "Currently on step 18500\n",
      "Accuracy is:\n",
      "0.7076\n",
      "\n",
      "\n",
      "Currently on step 18600\n",
      "Accuracy is:\n",
      "0.7098\n",
      "\n",
      "\n",
      "Currently on step 18700\n",
      "Accuracy is:\n",
      "0.7082\n",
      "\n",
      "\n",
      "Currently on step 18800\n",
      "Accuracy is:\n",
      "0.7066\n",
      "\n",
      "\n",
      "Currently on step 18900\n",
      "Accuracy is:\n",
      "0.7026\n",
      "\n",
      "\n",
      "Currently on step 19000\n",
      "Accuracy is:\n",
      "0.7103\n",
      "\n",
      "\n",
      "Currently on step 19100\n",
      "Accuracy is:\n",
      "0.7127\n",
      "\n",
      "\n",
      "Currently on step 19200\n",
      "Accuracy is:\n",
      "0.709\n",
      "\n",
      "\n",
      "Currently on step 19300\n",
      "Accuracy is:\n",
      "0.7024\n",
      "\n",
      "\n",
      "Currently on step 19400\n",
      "Accuracy is:\n",
      "0.7054\n",
      "\n",
      "\n",
      "Currently on step 19500\n",
      "Accuracy is:\n",
      "0.7143\n",
      "\n",
      "\n",
      "Currently on step 19600\n",
      "Accuracy is:\n",
      "0.7119\n",
      "\n",
      "\n",
      "Currently on step 19700\n",
      "Accuracy is:\n",
      "0.7132\n",
      "\n",
      "\n",
      "Currently on step 19800\n",
      "Accuracy is:\n",
      "0.7119\n",
      "\n",
      "\n",
      "Currently on step 19900\n",
      "Accuracy is:\n",
      "0.7066\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(20000):\n",
    "        batch = ch.next_batch(100)\n",
    "        sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:ch.test_images,y_true:ch.test_labels, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
